Things to Learn:

- Backpropogation (Andrej Karpathy has a video on this, maybe just watch all his videos, theyre golden)
- Batch and Layer normalisation
- THEN move on to GPT 2 video
- More recent GPT hacks and advances (many of which are shown openly by deepseek)
- Might be useful to breifly go over previously learned things with a fresh, core, and much deeper understanding e.g. RNNs, Convnets, Simple MLP, Encoder Decoders
(MAKE SURE TO ALWAYS TEST PRACTICALLY, IT ACTUALLY DOESN'T TAKE THAT LONG), REAL KNOWLEDGE AND INTUTION IS VERY IMPORTANT
- RAG (the main purpose here)
- C / CUDA / OpenCL - Learning to completely optimise and create chatgpt in raw C and CUDA showing you understand EVERYTHING



Random notes

# In order to generate more accurate tokens by validating and ranking outcomes:
- Beaming and top-p
- Candidate reranking (using a separate bi directional ranking model, possibly like BERT)
- Using fine tuned embeddings model as rankers? 
- Delegating to expert or fine tuned models for info (MoE or Mixture of Experts)


- Lossless compression of model weights is an area of active research (so we can run very large models on very small machines)
- Lossy compression is also very good, e.g. quantization of model weigths, but comes at a slight cost


maybe the REAL future direction:
Is not just similating what individuals do to replicate thought,
but simulating communities, a bit like in MoE models.

Creating a sort of conversation, where models / experts continuously generate, and revalidate one another, keeping the best ideas, then refeeding them into the correct models as training data.
This, combined with real world or online access as a test ground, to also validate these adeas, not just through ranking, could create real life automatic idea generation and evolution,



###
Other notes:
Using softmax on the wei (attention block) makes use of exponentials, so more extreme values become more amplified
This can be good in some cases, where when generating values, we want them to be more predetermined and right.
But what about when what is right is more relaxed? Or when we want to explore what is right?
It would still output correct things, but be less consistent in the way it says it.
This might be good for trading or other things where we are likely to make use of candidate re-ranking.
Our results might be a little more varied.

###
More startup ideas:
Anything involving prediction, and involved communication of previous tokens to the most recent, apply LLMs to them!
e.g. where will I go next? Predicting the next gene? Predicting
sentiment analysis

encoder decoder transformers - likely used for generating different output like audio
the keys come from x, but y queries and values come from somewhere else.
This is called cross attention


#### 

Multi headed attention:


Multi headed attention is where we use multiple smaller Attention Heads in parallel (which would amount to the size of the original solo attention head), then simply combining / concatenating the output vectors
The line of reasoning here is that each head will likely specialise / diversify, and when combined, the overall output will be more balanced, and rich in the encoded info.

In terms of the concern whereby the heads might converge to the same local minima, the randomised start weights will help with this, but the fact that these are also being combined and fed into other linear layers which will choose to weight each head differently in its own output, alongside the fact that backprogogation will seek to minimize the cost function means that diversification will happen if it benefits the cost function.

Additionally, this concept can be applied to many other areas of machine learning. E.g. Used simply in deep learning networks for the same reason to improve generalization

You can add to this concept, giving each subnetwork different data views, or different input params, and different shapes
Or combine networks that use different algorithms (stacking), or Boosting (e.g., AdaBoost, Gradient Boosting Machines)
